{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris() # The iris dataset is a classic and very easy multi-class classification dataset.\n",
    "\n",
    "#  The Iris dataset is used for supervised machine learning tasks, particularly for classification. It contains four features (sepal length, sepal width, petal length, and petal width)\n",
    "#  and three classes of iris plants (setosa, versicolor, and virginica). The goal of many machine learning exercises using this dataset is to build a model that can classify iris plants \n",
    "#  into one of these three species based on their feature measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data # iris data set load. This data represents the measurements of the four features of 150 iris flowers and the corresponding iris species.\n",
    "# X is a common name for the feature matrix in machine learning. The feature matrix is the two-dimensional array of features that represents the data set.\n",
    "# It's used to store the features of the data set. Each row represents a sample, and each column represents a feature.\n",
    "# sample is a single data point or observation. In iris context would be sepal length, sepal width, petal length, and petal width\n",
    "# feature is an individual measurable property of a phenomenon being observed. In iris context would be setosa, versicolor, and virginica\n",
    "# feature is the variable that we are measuring, and the sample is the measurement or value of the variable.\n",
    "\n",
    "\n",
    "Y = iris.target # iris data set label load\n",
    "\n",
    "# .target is the label of the data set. The label is the value that we want to predict from the data set.\n",
    "\n",
    "# .data is used to train the model, .target is used to test the model\n",
    "\n",
    "# X will be the data, and Y will be the labels, we use the labels to predict the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y) # np.unique() is used to find the unique elements of an array. In this case, it's used to find the unique elements of the Y array, which are the labels of the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is: (150, 4)\n",
      "The shape of label is: (150,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the data is: {X.shape}\\nThe shape of label is: {Y.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The object in the label: 2\n",
      "Is represented by the object in the data: [6.3 3.3 6.  2.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'The object in the label: {Y[100]}\\nIs represented by the object in the data: {X[100]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTrainTestSplit(X,y,percentage_of_data_set_used_for_testing): # X is the data set, y is the label\n",
    "\n",
    "    idx = np.random.permutation(np.arange(X.shape[0])) # here the idx is a random permutation of the numbers from 0 to the number of rows in the data set.\n",
    "    #shape[0] is the number of rows in the data set. Here are 150 rows in the data set. The permutation is a random reordering of the numbers from 0 to 149.\n",
    "\n",
    "    testSize = int(np.floor(percentage_of_data_set_used_for_testing*X.shape[0])) # testSize is the number of rows in the test set. The test_size parameter is the percentage \n",
    "    #of the data set that will be used for testing.\n",
    "\n",
    "    # idx is an array of random numbers from 0 to the number of rows in the data set(150). The testSize is the number of rows in the test set.\n",
    "\n",
    "    testIdx = idx[:testSize] # testIdx is recieving the first 30 values of the idx array. The first 30 values of the idx array are the first 30 random numbers from 0 to 149.\n",
    "\n",
    "    trainIdx = idx[testSize:] # trainIdx is recieving the last 120 values of the idx array. The last 120 values of the idx array are the last 120 random numbers from 0 to 149.\n",
    "    Xtrain = X[trainIdx,:] # Xtrain is recieving the rows of the X array that correspond to the values in the trainIdx array. The trainIdx array is the last 120 random numbers from 0 to 149.\n",
    "    ytrain = y[trainIdx] # ytrain is recieving the rows of the y array that correspond to the values in the trainIdx array. The trainIdx array is the last 120 random numbers from 0 to 149.\n",
    "    Xtest = X[testIdx,:] # Xtest is recieving the rows of the X array that correspond to the values in the testIdx array. The testIdx array is the first 30 random numbers from 0 to 149.\n",
    "    ytest = y[testIdx] # ytest is recieving the rows of the y array that correspond to the values in the testIdx array. The testIdx array is the first 30 random numbers from 0 to 149.\n",
    "\n",
    "    return Xtrain,Xtest,ytrain,ytest # The function is returning the Xtrain, Xtest, ytrain, and ytest arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of rows in the data set: 150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Numbers of rows in the data set: {X.shape[0]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = myTrainTestSplit(X,Y,0.2)\n",
    "\n",
    "#Xtrain is the data set that will be used to train the model. \n",
    "# Xtest is the data set that will be used to test the model. \n",
    "# ytrain is the label that will be used to train the model.\n",
    "# ytest is the label that will be used to test the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim of Xtrain: 2\n",
      "ndim of Xtest: 2\n",
      "ndim of ytrain: 1\n",
      "ndim of ytest: 1\n",
      "\n",
      "\n",
      "The shape of Xtrain: (120, 4)\n",
      "The shape of Xtest: (30, 4)\n",
      "The shape of ytrain: (120,)\n",
      "The shape of ytest: (30,)\n",
      "\n",
      "\n",
      "The shape using newaxis of Xtrain: (120, 1, 4)\n",
      "The shape using newaxis of Xtest: (1, 30, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# euclidian distance is the distance between two points in a plane.\n",
    "# The formula for calculating the euclidian distance is the square root of the sum of the squared differences between the x and y coordinates of the two points.\n",
    "# sqrt((x1-x2)^2+(y1-y2)^2)\n",
    "print(f'ndim of Xtrain: {Xtrain.ndim}\\nndim of Xtest: {Xtest.ndim}\\nndim of ytrain: {ytrain.ndim}\\nndim of ytest: {ytest.ndim}\\n')\n",
    "print(f'\\nThe shape of Xtrain: {Xtrain.shape}\\nThe shape of Xtest: {Xtest.shape}\\nThe shape of ytrain: {ytrain.shape}\\nThe shape of ytest: {ytest.shape}\\n')\n",
    "\n",
    "#knowing the shape of Xtrain is (120,4) and the shape of Xtest is (30,4) we can assume they have the same number of columns, but different number of rows.\n",
    "\n",
    "D = np.sqrt(np.sum((Xtrain[:,np.newaxis,:]-Xtest[np.newaxis,:,:])**2,axis=2)) # D is the euclidian distance between the Xtrain and Xtest arrays. \n",
    "\n",
    "# Xtrain[:,np.newaxis,:] is the Xtrain array with a new axis added. The new axis is added between the first and second axis.\n",
    "# Xtest[np.newaxis,:,:] is the Xtest array with a new axis added. The new axis is added at the beginning of the array.\n",
    "# The new axis is added to the Xtrain and Xtest arrays to make it possible to subtract the arrays from each other.\n",
    "# They have to have the same number of dimensions to be subtracted from each other.\n",
    "\n",
    "D.shape\n",
    "\n",
    "print(f'\\nThe shape using newaxis of Xtrain: {Xtrain[:,np.newaxis,:].shape}\\nThe shape using newaxis of Xtest: {Xtest[np.newaxis,:,:].shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance of the first object in the test set to all the objects in the training set is:\n",
      "[6.47688197 6.13432963 3.73764632 6.67083203 2.39582971 2.26495033\n",
      " 6.43117408 2.1023796  2.78926514 6.44592895 2.03715488 2.24944438\n",
      " 2.14009346 2.64952826 1.81659021 6.06712452 3.78681925 6.71788657\n",
      " 3.55808937 6.55362495 1.99749844 1.72336879 2.463737   6.4007812\n",
      " 3.31209903 2.64952826 6.25139984 0.41231056 3.04959014 3.58887169]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'The distance of the first object in the test set to all the objects in the training set is:\\n{D[0]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndix = np.argsort(D, axis=0) # ndix is the index of the sorted D array. The axis parameter is the axis along which the array is sorted.\n",
    "#argsort is used to sort the array. The axis parameter is the axis along which the array is sorted. The axis parameter is the axis along which the array is sorted.\n",
    "\n",
    "ndix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ndix[:10,15] # idx is the first 10 rows and the 15th column of the ndix array. The first 10 rows of the ndix array are the first 10 objects in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=0, count=10)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.mode(ytrain[idx]) # stats.mode() is used to find the most common value in an array. In this case, it's used to find the most common value in the ytrain array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[15] # ytest[15] is the label of the 15th object in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3) # knn is the KNeighborsClassifier object. The n_neighbors parameter is the number of neighbors to use for the classification.\n",
    "# for the iris data set, the n_neighbors parameter is 3.\n",
    "\n",
    "knn.fit(Xtrain, ytrain) # knn.fit() is used to train the model. The Xtrain array is the data set that will be used to train the model. \n",
    "# The ytrain array is the label that will be used to train the model.\n",
    "\n",
    "y_pred = knn.predict(Xtest) # knn.predict() is used to predict the label of the Xtest array. The Xtest array is the data set that will be used to test the model.\n",
    "\n",
    "accuracy = accuracy_score(ytest, y_pred) # accuracy_score() is used to calculate the accuracy of the model. The ytest array is the label that will be used to test the model.\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
